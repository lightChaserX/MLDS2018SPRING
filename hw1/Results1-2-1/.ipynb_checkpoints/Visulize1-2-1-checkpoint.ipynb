{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571\n",
      "Iteration   0: loss 0.0270767665\n",
      "Iteration   1: loss 0.0264744486\n",
      "Iteration   2: loss 0.0261055692\n",
      "Iteration   3: loss 0.0261439416\n",
      "Iteration   4: loss 0.0259387371\n",
      "Iteration   5: loss 0.0259681234\n",
      "Iteration   6: loss 0.0259357545\n",
      "Iteration   7: loss 0.0259482047\n",
      "Iteration   8: loss 0.0259657106\n",
      "Iteration   9: loss 0.0259137319\n",
      "Iteration  10: loss 0.0259185401\n",
      "Iteration  11: loss 0.0259318346\n",
      "Iteration  12: loss 0.0259245225\n",
      "Iteration  13: loss 0.0259371184\n",
      "Iteration  14: loss 0.0259552536\n",
      "Iteration  15: loss 0.0258983964\n",
      "Iteration  16: loss 0.0259328908\n",
      "Iteration  17: loss 0.0259296995\n",
      "Iteration  18: loss 0.0260470573\n",
      "Iteration  19: loss 0.0262149262\n",
      "Iteration  20: loss 0.0260519836\n",
      "Iteration  21: loss 0.0259027639\n",
      "Iteration  22: loss 0.0259255194\n",
      "Iteration  23: loss 0.0259574162\n",
      "Iteration  24: loss 0.0261408228\n",
      "Iteration  25: loss 0.0258734427\n",
      "Iteration  26: loss 0.0258987710\n",
      "Iteration  27: loss 0.0259602112\n",
      "Iteration  28: loss 0.0258574992\n",
      "Iteration  29: loss 0.0258548257\n",
      "Iteration  30: loss 0.0259589058\n",
      "Iteration  31: loss 0.0260748070\n",
      "Iteration  32: loss 0.0262860862\n",
      "Iteration  33: loss 0.0259179092\n",
      "Iteration  34: loss 0.0258025063\n",
      "Iteration  35: loss 0.0258325449\n",
      "Iteration  36: loss 0.0260086751\n",
      "Iteration  37: loss 0.0258085600\n",
      "Iteration  38: loss 0.0255570973\n",
      "Iteration  39: loss 0.0254051780\n",
      "Iteration  40: loss 0.0252174710\n",
      "Iteration  41: loss 0.0255627809\n",
      "Iteration  42: loss 0.0263534350\n",
      "Iteration  43: loss 0.0285940990\n",
      "Iteration  44: loss 0.0267212545\n",
      "Iteration  45: loss 0.0260329004\n",
      "Iteration  46: loss 0.0260549228\n",
      "Iteration  47: loss 0.0255599556\n",
      "Iteration  48: loss 0.0254363785\n",
      "Iteration  49: loss 0.0252429196\n",
      "Iteration  50: loss 0.0246321340\n",
      "Iteration  51: loss 0.0237256576\n",
      "Iteration  52: loss 0.0230264356\n",
      "Iteration  53: loss 0.0256149965\n",
      "Iteration  54: loss 0.0220226319\n",
      "Iteration  55: loss 0.0223247457\n",
      "Iteration  56: loss 0.0265264813\n",
      "Iteration  57: loss 0.0203860004\n",
      "Iteration  58: loss 0.0201157195\n",
      "Iteration  59: loss 0.0166103745\n",
      "Iteration  60: loss 0.0150557467\n",
      "Iteration  61: loss 0.0137787170\n",
      "Iteration  62: loss 0.0149118963\n",
      "Iteration  63: loss 0.0137375903\n",
      "Iteration  64: loss 0.0153260195\n",
      "Iteration  65: loss 0.0133659778\n",
      "Iteration  66: loss 0.0117072701\n",
      "Iteration  67: loss 0.0108632900\n",
      "Iteration  68: loss 0.0116329517\n",
      "Iteration  69: loss 0.0132770805\n",
      "Iteration  70: loss 0.0114562692\n",
      "Iteration  71: loss 0.0130363850\n",
      "Iteration  72: loss 0.0114762002\n",
      "Iteration  73: loss 0.0101820018\n",
      "Iteration  74: loss 0.0094266416\n",
      "Iteration  75: loss 0.0098115877\n",
      "Iteration  76: loss 0.0112371289\n",
      "Iteration  77: loss 0.0112843420\n",
      "Iteration  78: loss 0.0139676617\n",
      "Iteration  79: loss 0.0120890594\n",
      "Iteration  80: loss 0.0122921946\n",
      "Iteration  81: loss 0.0095460662\n",
      "Iteration  82: loss 0.0098607449\n",
      "Iteration  83: loss 0.0118916001\n",
      "Iteration  84: loss 0.0106071814\n",
      "Iteration  85: loss 0.0099754220\n",
      "Iteration  86: loss 0.0091228043\n",
      "Iteration  87: loss 0.0088784326\n",
      "Iteration  88: loss 0.0096010667\n",
      "Iteration  89: loss 0.0098521254\n",
      "Iteration  90: loss 0.0104732078\n",
      "Iteration  91: loss 0.0095307451\n",
      "Iteration  92: loss 0.0089076325\n",
      "Iteration  93: loss 0.0082975285\n",
      "Iteration  94: loss 0.0082245174\n",
      "Iteration  95: loss 0.0084650778\n",
      "Iteration  96: loss 0.0090059235\n",
      "Iteration  97: loss 0.0125352984\n",
      "Iteration  98: loss 0.0108415297\n",
      "Iteration  99: loss 0.0105636999\n",
      "Iteration 100: loss 0.0088693111\n",
      "Iteration 101: loss 0.0093164942\n",
      "Iteration 102: loss 0.0118646544\n",
      "Iteration 103: loss 0.0106731267\n",
      "Iteration 104: loss 0.0128364822\n",
      "Iteration 105: loss 0.0095559894\n",
      "Iteration 106: loss 0.0082266537\n",
      "Iteration 107: loss 0.0087903086\n",
      "Iteration 108: loss 0.0093047692\n",
      "Iteration 109: loss 0.0104246207\n",
      "Iteration 110: loss 0.0088671580\n",
      "Iteration 111: loss 0.0079786145\n",
      "Iteration 112: loss 0.0078931605\n",
      "Iteration 113: loss 0.0081906930\n",
      "Iteration 114: loss 0.0090845916\n",
      "Iteration 115: loss 0.0087707658\n",
      "Iteration 116: loss 0.0085555581\n",
      "Iteration 117: loss 0.0079396192\n",
      "Iteration 118: loss 0.0073829490\n",
      "Iteration 119: loss 0.0072734130\n",
      "Iteration 120: loss 0.0074592347\n",
      "Iteration 121: loss 0.0081391045\n",
      "Iteration 122: loss 0.0081704159\n",
      "Iteration 123: loss 0.0088094559\n",
      "Iteration 124: loss 0.0080287508\n",
      "Iteration 125: loss 0.0078994169\n",
      "Iteration 126: loss 0.0073332309\n",
      "Iteration 127: loss 0.0069671185\n",
      "Iteration 128: loss 0.0069272201\n",
      "Iteration 129: loss 0.0071975994\n",
      "Iteration 130: loss 0.0082877930\n",
      "Iteration 131: loss 0.0092814087\n",
      "Iteration 132: loss 0.0132077051\n",
      "Iteration 133: loss 0.0107497184\n",
      "Iteration 134: loss 0.0091818231\n",
      "Iteration 135: loss 0.0073753843\n",
      "Iteration 136: loss 0.0078978883\n",
      "Iteration 137: loss 0.0104730935\n",
      "Iteration 138: loss 0.0100816288\n",
      "Iteration 139: loss 0.0115513574\n",
      "Iteration 140: loss 0.0082809874\n",
      "Iteration 141: loss 0.0074303132\n",
      "Iteration 142: loss 0.0089683123\n",
      "Iteration 143: loss 0.0093000607\n",
      "Iteration 144: loss 0.0110733150\n",
      "Iteration 145: loss 0.0084611849\n",
      "Iteration 146: loss 0.0073231366\n",
      "Iteration 147: loss 0.0082729323\n",
      "Iteration 148: loss 0.0088917137\n",
      "Iteration 149: loss 0.0098440409\n",
      "Iteration 150: loss 0.0079783337\n",
      "Iteration 151: loss 0.0069289664\n",
      "Iteration 152: loss 0.0070928205\n",
      "Iteration 153: loss 0.0076957930\n",
      "Iteration 154: loss 0.0084631549\n",
      "Iteration 155: loss 0.0078216274\n",
      "Iteration 156: loss 0.0069610800\n",
      "Iteration 157: loss 0.0065991996\n",
      "Iteration 158: loss 0.0066659055\n",
      "Iteration 159: loss 0.0072392359\n",
      "Iteration 160: loss 0.0077845179\n",
      "Iteration 161: loss 0.0085373919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-163:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 50, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method DataLoaderIter.__del__ of <torch.utils.data.dataloader.DataLoaderIter object at 0x7f880d6eac18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 333, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 319, in _shutdown_workers\n",
      "    self.data_queue.get()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/queues.py\", line 337, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/multiprocessing/reductions.py\", line 70, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/resource_sharer.py\", line 87, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/connection.py\", line 487, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/home/pixiym/miniconda3/envs/py3k/lib/python3.6/multiprocessing/connection.py\", line 614, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-30ca883e6f1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Does the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunning_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_data\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, os, csv, argparse\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import *\n",
    "\n",
    "\"\"\"\n",
    "TODO: Execture\n",
    "\"\"\"\n",
    "if __name__ == '__main__':\n",
    "    num_data = 2000\n",
    "    MAX_Iter = 1000 #20 itr/epoch\n",
    "    BATCH_SIZE = 100\n",
    "    \n",
    "    num_func = 1\n",
    "    num_model = 0\n",
    "    \n",
    "    exec('f = f%s' % num_func)\n",
    "    exec('net = Net%s().cuda().double() ' % num_model)\n",
    "    \n",
    "    print(\"number of model parameters %d\" % model_params(net))\n",
    "    \n",
    "    weight_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_weight.dat'\n",
    "    \n",
    "    loader = UtiData.DataLoader(dataset=make_feature(num_data, f), \n",
    "                                batch_size=BATCH_SIZE, \n",
    "                                shuffle=True, num_workers=1)\n",
    "    \n",
    "    #criterion = nn.MSELoss().cuda()\n",
    "    criterion = nn.MSELoss().cuda()\n",
    "    \n",
    "    #optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.005)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), weight_decay=0.0000)\n",
    "    \n",
    "    loss_total = []\n",
    "    all_params = np.array([])\n",
    "    for iter in range(0,MAX_Iter):\n",
    "        running_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        for step_i, (x_batch, y_batch) in enumerate(loader):\n",
    "            if x_batch.size(0) != BATCH_SIZE or y_batch.size(0) != BATCH_SIZE:\n",
    "                continue\n",
    "            \n",
    "            x_input = Variable(x_batch.type(torch.DoubleTensor).cuda())\n",
    "            y_input = Variable(y_batch.type(torch.DoubleTensor).cuda())\n",
    "            \n",
    "            y_hat = net(x_input)\n",
    "            \n",
    "            loss = criterion(y_hat, y_input)\n",
    "            loss.backward()\n",
    "        \n",
    "            # Does the update\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data[0]\n",
    "            \n",
    "        loss_total.append(running_loss/(num_data/BATCH_SIZE))\n",
    "        print('Iteration %3d: loss %.10f' % (iter, running_loss/(num_data/BATCH_SIZE)))\n",
    "        \n",
    "        if not iter % (3*num_data//BATCH_SIZE):\n",
    "            epoch_params = np.array([])\n",
    "            for one_name, one_param in net.named_parameters():\n",
    "                if 'weight' in one_name:\n",
    "                    epoch_params = np.append(epoch_params, one_param.cpu().data.numpy())\n",
    "            if not all_params.size:\n",
    "                all_params = epoch_params\n",
    "            else:\n",
    "                all_params = np.vstack((all_params, epoch_params))\n",
    "            weight_df = pd.DataFrame(np.transpose(all_params))\n",
    "            weight_df.to_csv(weight_save_file_name, index=False)\n",
    "\n",
    "    x_show = np.linspace(0,1,num_data) \n",
    "    y_show = f(x_show)\n",
    "    yhat_test = net(Variable(torch.from_numpy(x_show).unsqueeze(1).type(torch.DoubleTensor).cuda())).data.cpu().numpy().squeeze(1)\n",
    "    \n",
    "    yhat_show = []\n",
    "    for i in range(len(yhat_test)):\n",
    "        yhat_show.append(yhat_test[i])\n",
    "    \n",
    "    plt.figure(1), \n",
    "    plt.plot(x_show, y_show, 'b--'), \n",
    "    plt.plot(x_show, yhat_test, 'g'), plt.grid(True)\n",
    "\n",
    "    plt.figure(2), \n",
    "    plt.semilogy(loss_total, 'r')\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('MSE'), plt.grid(True)\n",
    "    \n",
    "    print('Finish running the code!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = 'rgb'\n",
    "num_func = 0\n",
    "num_model = 0\n",
    "weight_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_weight.dat'\n",
    "weight_read = pd.read_csv(weight_save_file_name, header=None)\n",
    "print(weight_read[0])\n",
    "#plt.figure(1), \n",
    "#plt.plot(data_read[\"x\"], data_read[\"yhat\"], color[num_model], label='Model'+str(num_model)), plt.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "color = 'rgb'\n",
    "num_func = 2\n",
    "num_model = 0\n",
    "for times in range(0,7):\n",
    "    data_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_data' + str(times) + '.dat'\n",
    "    loss_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_loss' + str(times) + '.dat'\n",
    "    weight_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_weight' + str(times) + '.dat'\n",
    "    bias_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_bias' + str(times) + '.dat'\n",
    "    data_read = pd.read_csv(data_save_file_name)\n",
    "    plt.figure(1), \n",
    "    plt.plot(data_read[\"x\"], data_read[\"yhat\"], color[times%3], label='Model'+str(num_model)), plt.grid(True)\n",
    "\n",
    "    loss_read = pd.read_csv(loss_save_file_name)\n",
    "    plt.figure(2), \n",
    "    plt.semilogy(loss_read, color[times%3], label='Model'+str(num_model))\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    weight_read = pd.read_csv(weight_save_file_name, header=None)\n",
    "    plt.figure(3), plt.plot(weight_read[2:-1], label='Times'+str(times))\n",
    "    \n",
    "    bias_read = pd.read_csv(bias_save_file_name, header=None)\n",
    "    plt.figure(4), plt.plot(bias_read[2:-1], label='Times'+str(times))\n",
    "\n",
    "plt.figure(1), plt.plot(data_read[\"x\"], data_read[\"y\"], 'k--', label='Ground truth'), plt.grid(True)\n",
    "plt.legend(loc=0)\n",
    "plt.figure(2), plt.legend(loc=0)\n",
    "plt.figure(3), plt.legend(loc=0)\n",
    "plt.figure(4), plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os, csv, argparse\n",
    "import pandas as pd\n",
    "sys.path.append('..')\n",
    "from sklearn.decomposition import PCA\n",
    "from utility import *\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "num_model = 0\n",
    "times = 0\n",
    "samples_weight = np.array([])\n",
    "for num_func in range(0,2):\n",
    "    data_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_data' + str(times) + '.dat'\n",
    "    loss_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_loss' + str(times) + '.dat'\n",
    "    weight_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_weight' + str(times) + '.dat'\n",
    "    bias_save_file_name = 'func' + str(num_func) + '_model' + str(num_model) + '_bias' + str(times) + '.dat'\n",
    "    weight_read = pd.read_csv(weight_save_file_name, header=None)    \n",
    "    bias_read = pd.read_csv(bias_save_file_name, header=None)\n",
    "    if not samples_weight.size:\n",
    "        samples_weight = weight_read\n",
    "    samples_weight = np.hstack((samples_weight, weight_read))\n",
    "\n",
    "pc1 = pca.fit_transform(np.transpose(samples_weight))\n",
    "plt.figure,  plt.plot(pc1[0:333,0], pc1[0:333,1], 'b')\n",
    "plt.plot(pc1[0,0], pc1[0,1], 'ro')\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.quiver(pc1[301,0], pc1[301,1], pc1[302,0]-pc1[301,0], pc1[302,1]-pc1[301,1], \n",
    "          angles='xy', scale_units='xy', color='b', width=0.008)\n",
    "ax.quiver(pc1[201,0], pc1[201,1], pc1[202,0]-pc1[201,0], pc1[202,1]-pc1[201,1], \n",
    "          angles='xy', scale_units='xy', color='b', width=0.008)\n",
    "ax.quiver(pc1[101,0], pc1[101,1], pc1[102,0]-pc1[101,0], pc1[102,1]-pc1[101,1], \n",
    "          angles='xy', scale_units='xy', color='b', width=0.008)\n",
    "ax.quiver(pc1[10,0], pc1[10,1], pc1[11,0]-pc1[10,0], pc1[11,1]-pc1[10,1], \n",
    "          angles='xy', scale_units='xy', color='b', width=0.008)\n",
    "\n",
    "\n",
    "#fig = plt.figure()\n",
    "#axes = fig.add_subplot(111)\n",
    "#arrowplot(axes, pc1[:,0], pc1[:,1], dspace=0.0, hl=0.1, hw=5, c='r' ) \n",
    "#plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
