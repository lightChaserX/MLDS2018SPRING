{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of model params 21840\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([100, 1, 28, 28])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3bd55122e787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Convert torch tensor to Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m#images = Variable(images.view(-1, 28*28))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/torchvision-0.2.0-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# to return a PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'L'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2445\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2391\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2392\u001b[0m             im = im._new(\n\u001b[0;32m-> 2393\u001b[0;31m                 \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2394\u001b[0m                 )\n\u001b[1;32m   2395\u001b[0m             \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append('..')\n",
    "from utility import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Hyper Parameters \n",
    "input_size    = 784\n",
    "hidden_size   = 500\n",
    "num_classes   = 10\n",
    "num_epochs    = 5\n",
    "batch_size    = 100\n",
    "learning_rate = 0.001\n",
    "num_model     = 0\n",
    "\n",
    "# MNIST Dataset \n",
    "train_dataset, test_dataset = fetch_mnist_data(dir='../data')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "exec('net = CNN_Net%s().cuda().double() ' % num_model)\n",
    "    \n",
    "\n",
    "print(\"num of model params %d\" % model_params(net))\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss().cuda() \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)  \n",
    "\n",
    "##################################################################################################\n",
    "loss_total = []\n",
    "accu_total = []\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    \n",
    "    test_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Convert torch tensor to Variable\n",
    "        #images = Variable(images.view(-1, 28*28))\n",
    "        images = Variable(images.type(torch.DoubleTensor)).cuda()\n",
    "        labels = Variable(labels.type(torch.LongTensor)).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "    \n",
    "        running_correct += torch.sum(pred == labels.data)\n",
    "        running_loss += loss.data[0]\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    cur_accu = running_correct/len(train_loader)\n",
    "    cur_loss = running_loss/len(train_loader)\n",
    "    \n",
    "    loss_total.append(cur_loss)\n",
    "    accu_total.append(cur_accu)\n",
    "    print ('Epoch [%d/%d], Accu:%.4f Loss: %.4f' % (epoch+1, num_epochs, cur_accu, cur_loss))\n",
    "    \n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(loss_total, 'k')\n",
    "plt.figure(2)\n",
    "plt.plot(accu_total, 'k')        \n",
    "plt.show()\n",
    "    \n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    #images = Variable(images.view(-1, 28*28))\n",
    "    images = Variable(images.type(torch.DoubleTensor)).cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu().numpy() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "# Save the Model\n",
    "torch.save(net.state_dict(), 'model.pkl') #net.load_state_dict(torch.load('model.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{140412363526472: 'conv1.weight', 140412363526920: 'bn1.weight', 140412363526984: 'bn1.bias', 140412363527048: 'bn1.running_mean', 140412363527112: 'bn1.running_var', 140412363528712: 'layer1.0.conv1.weight', 140412363529160: 'layer1.0.bn1.weight', 140412363529224: 'layer1.0.bn1.bias', 140412363529288: 'layer1.0.bn1.running_mean', 140412363529352: 'layer1.0.bn1.running_var', 140412363530184: 'layer1.0.conv2.weight', 140412363473352: 'layer1.0.bn2.weight', 140412363473416: 'layer1.0.bn2.bias', 140412363473480: 'layer1.0.bn2.running_mean', 140412363473544: 'layer1.0.bn2.running_var', 140412363474376: 'layer1.1.conv1.weight', 140412363474824: 'layer1.1.bn1.weight', 140412363474888: 'layer1.1.bn1.bias', 140412363474952: 'layer1.1.bn1.running_mean', 140412363475016: 'layer1.1.bn1.running_var', 140412363475848: 'layer1.1.conv2.weight', 140412363476296: 'layer1.1.bn2.weight', 140412363476360: 'layer1.1.bn2.bias', 140412363476424: 'layer1.1.bn2.running_mean', 140412363476488: 'layer1.1.bn2.running_var', 140412363483336: 'layer2.0.conv1.weight', 140412363483784: 'layer2.0.bn1.weight', 140412363483848: 'layer2.0.bn1.bias', 140412363483912: 'layer2.0.bn1.running_mean', 140412363483976: 'layer2.0.bn1.running_var', 140412363484808: 'layer2.0.conv2.weight', 140412363509896: 'layer2.0.bn2.weight', 140412363509960: 'layer2.0.bn2.bias', 140412363510024: 'layer2.0.bn2.running_mean', 140412363510088: 'layer2.0.bn2.running_var', 140412363481480: 'layer2.0.downsample.0.weight', 140412363481928: 'layer2.0.downsample.1.weight', 140412363481992: 'layer2.0.downsample.1.bias', 140412363482056: 'layer2.0.downsample.1.running_mean', 140412363482120: 'layer2.0.downsample.1.running_var', 140412363510856: 'layer2.1.conv1.weight', 140412363511304: 'layer2.1.bn1.weight', 140412363511368: 'layer2.1.bn1.bias', 140412363511432: 'layer2.1.bn1.running_mean', 140412363511496: 'layer2.1.bn1.running_var', 140412363512328: 'layer2.1.conv2.weight', 140412363512776: 'layer2.1.bn2.weight', 140412363512840: 'layer2.1.bn2.bias', 140412363512904: 'layer2.1.bn2.running_mean', 140412363512968: 'layer2.1.bn2.running_var', 140412363544328: 'layer3.0.conv1.weight', 140412363544776: 'layer3.0.bn1.weight', 140412363544840: 'layer3.0.bn1.bias', 140412363544904: 'layer3.0.bn1.running_mean', 140412363544968: 'layer3.0.bn1.running_var', 140412363545800: 'layer3.0.conv2.weight', 140412363546248: 'layer3.0.bn2.weight', 140412363546312: 'layer3.0.bn2.bias', 140412363546376: 'layer3.0.bn2.running_mean', 140412363546440: 'layer3.0.bn2.running_var', 140412363513736: 'layer3.0.downsample.0.weight', 140412363542920: 'layer3.0.downsample.1.weight', 140412363542984: 'layer3.0.downsample.1.bias', 140412363543048: 'layer3.0.downsample.1.running_mean', 140412363543112: 'layer3.0.downsample.1.running_var', 140412363555464: 'layer3.1.conv1.weight', 140412363555912: 'layer3.1.bn1.weight', 140412363555976: 'layer3.1.bn1.bias', 140412363556040: 'layer3.1.bn1.running_mean', 140412363556104: 'layer3.1.bn1.running_var', 140412363556936: 'layer3.1.conv2.weight', 140412363557384: 'layer3.1.bn2.weight', 140412363557448: 'layer3.1.bn2.bias', 140412363557512: 'layer3.1.bn2.running_mean', 140412363557576: 'layer3.1.bn2.running_var', 140412363109768: 'layer4.0.conv1.weight', 140412363110216: 'layer4.0.bn1.weight', 140412363110280: 'layer4.0.bn1.bias', 140412363110344: 'layer4.0.bn1.running_mean', 140412363110408: 'layer4.0.bn1.running_var', 140412363111240: 'layer4.0.conv2.weight', 140412363111688: 'layer4.0.bn2.weight', 140412363111752: 'layer4.0.bn2.bias', 140412363111816: 'layer4.0.bn2.running_mean', 140412363111880: 'layer4.0.bn2.running_var', 140412363558408: 'layer4.0.downsample.0.weight', 140412363558856: 'layer4.0.downsample.1.weight', 140412363108424: 'layer4.0.downsample.1.bias', 140412363108488: 'layer4.0.downsample.1.running_mean', 140412363108552: 'layer4.0.downsample.1.running_var', 140412363121032: 'layer4.1.conv1.weight', 140412363121544: 'layer4.1.bn1.weight', 140412363121608: 'layer4.1.bn1.bias', 140412363121672: 'layer4.1.bn1.running_mean', 140412363121736: 'layer4.1.bn1.running_var', 140412363122824: 'layer4.1.conv2.weight', 140412363123336: 'layer4.1.bn2.weight', 140412363123400: 'layer4.1.bn2.bias', 140412363123464: 'layer4.1.bn2.running_mean', 140412363123528: 'layer4.1.bn2.running_var', 140412363157576: 'fc.weight', 140412363157640: 'fc.bias'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    \n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    \n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    param_map = {id(v): k for k, v in params.items()}\n",
    "    print(param_map)\n",
    "    \n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    \n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d'% v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "from torchvision import models\n",
    "inputs = torch.randn(1,3,224,224)\n",
    "resnet18 = models.resnet18()\n",
    "y = resnet18(Variable(inputs))\n",
    "# print(y)\n",
    "\n",
    "g = make_dot(y, resnet18.state_dict())\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1c8ed625a6e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3k/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model.pkl'"
     ]
    }
   ],
   "source": [
    "net.load_state_dict(torch.load('model.pkl'))\n",
    "    \n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    #images = Variable(images.view(-1, 28*28))\n",
    "    images = Variable(images.type(torch.DoubleTensor)).cuda()\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted.cpu().numpy() == labels).sum()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
